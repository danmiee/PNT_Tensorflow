{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOMQmNzWfkXD"
      },
      "outputs": [],
      "source": [
        "#1201\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "##def dataset(train_size=100): # numpy\n",
        "##     np.random.seed(1)\n",
        "##     x = np.linspace(0.0, 10.0, num=train_size)\n",
        "####     y = x**3 + x**2 + x + 4.0\n",
        "##     y = 3.0*x - 10.0\n",
        "####     y+= np.random.randn(train_size)*2.0\n",
        "##     y += np.random.normal(loc=0.0, scale=2.0, size=train_size)\n",
        "##     return x, y\n",
        "\n",
        "def dataset(train_size=100): # tensorflow    \n",
        "     tf.random.set_seed(1)\n",
        "     x = tf.linspace(0.0, 10.0, num=train_size)\n",
        "##     y = x**3 + x**2 + x + 4.0\n",
        "     y = 3.0*x - 10.0\n",
        "     y += tf.random.normal([train_size], mean=0.0, stddev = 2.0)\n",
        "     return x, y\n",
        "x, y_true = dataset(20)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=1, input_dim=1))\n",
        "##model.add(tf.keras.layers.Dense(units=1, input_shape=(1,))) # [1]\n",
        "##model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=(1,))])\n",
        "model.summary()\n",
        "\n",
        "##opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "##opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse') # 'mean_squared_error'\n",
        "##model.compile(optimizer='sgd', loss='mse') # 'sgd', 'adam', 'rmsprop'\n",
        "\n",
        "# 0: silent, 1:progress bar,  2: one line per epoch \n",
        "ret = model.fit(x, y_true, epochs=100, batch_size=4, verbose=2)\n",
        "print(\"len(model.layers):\", len(model.layers)) # 1\n",
        "\n",
        "loss = ret.history['loss']\n",
        "print(\"loss:\", loss[-1])\n",
        "#print(model.get_weights())  # weights, bias\n",
        "print(\"weights:\", model.layers[0].weights[0].numpy())\n",
        "print(\"bias:\", model.layers[0].weights[1].numpy()) # model.layers[0].bias.numpy()\n",
        "\n",
        "plt.plot(loss)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(x, y_true)\n",
        "y_pred = model.predict(x)\n",
        "plt.plot(x, y_pred, color='red')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vab7ns3ffxhE"
      },
      "outputs": [],
      "source": [
        "#1202\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_data = np.array([ # t = 1*x0 + 2*x1 + 3\n",
        "#  x0, x1, t      \n",
        " [ 1,  0,  4],\n",
        " [ 2,  0,  5],\n",
        " [ 3,  0,  6],\n",
        " [ 4,  0,  7],\n",
        " [ 1,  1,  6],\n",
        " [ 2,  1,  7],\n",
        " [ 3,  1,  8],\n",
        " [ 4,  1,  9]], dtype=np.float32)\n",
        "\n",
        "X      = train_data[:, :-1]\n",
        "y_true = train_data[:, -1:]  # t\n",
        "##y_true += np.reshape(np.random.randn(len(y_true))*2.0, (-1, 1)) \n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(units=1, input_dim=2)) # input_shape=(2,)\n",
        "model.summary()\n",
        "\n",
        "##opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "##opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse') # 'mean_squared_error'\n",
        "##model.compile(optimizer='sgd', loss='mse') # 'sgd', 'adam', 'rmsprop'\n",
        "\n",
        "# 0: silent, 1:progress bar,  2: one line per epoch \n",
        "ret = model.fit(X, y_true, epochs=100, batch_size=4, verbose=2)\n",
        "y_pred = model.predict(X)\n",
        "print(\"y_pred:\", y_pred)\n",
        "print(\"len(model.layers):\", len(model.layers)) # 1\n",
        "\n",
        "loss = ret.history['loss']\n",
        "print(\"loss:\", loss[-1])\n",
        "#print(model.get_weights())\n",
        "print(\"weights:\", model.layers[0].weights[0].numpy())\n",
        "print(\"bias:\", model.layers[0].weights[1].numpy()) # model.layers[0].bias.numpy()\n",
        "\n",
        "plt.plot(loss)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fH3HnzGbf1RT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x= tf.Tensor(\n",
            "[-5.         -4.4736843  -3.9473684  -3.4210525  -2.8947368  -2.368421\n",
            " -1.8421052  -1.3157892  -0.78947353 -0.26315784  0.26315784  0.789474\n",
            "  1.3157897   1.8421054   2.3684216   2.8947372   3.421053    3.9473686\n",
            "  4.4736843   5.        ], shape=(20,), dtype=float32)\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'y' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14804\\2422951751.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m##y_true /= max(y_true)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y='\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m# n-차 다항식 회귀\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ],
      "source": [
        "#1203\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def dataset(train_size=100): # tensorflow    \n",
        "     tf.random.set_seed(1)\n",
        "     x = tf.linspace(-5.0, 5.0, num=train_size)\n",
        "     y = 3.0*x**3 + 2.0*x**2 + x + 4.0\n",
        "     y += tf.random.normal([train_size], mean=0.0, stddev = 30.0)\n",
        "     return x, y\n",
        "x, y_true = dataset(20)\n",
        "##x /= max(x)       # 정규화\n",
        "##y_true /= max(y_true)\n",
        "print('x=',x)\n",
        "print('y=', y_true)\n",
        "# n-차 다항식 회귀\n",
        "n = 3\n",
        "X = np.ones(shape = (len(x), n+1), dtype=np.float32)\n",
        "##X[:, 0] = 1.0\n",
        "##X[:, 1] = x\n",
        "##X[:, 2] = x**2\n",
        "##X[:, 3] = x**3\n",
        "for i in range(1, n+1):\n",
        "     X[:, i] = x**i\n",
        "\n",
        "model=tf.keras.Sequential(\n",
        "        [tf.keras.layers.Dense(units=1, use_bias=False,input_shape=(n+1,))])\n",
        "model.summary()\n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "ret = model.fit(X, y_true, epochs=100, verbose=2)\n",
        "print(\"len(model.layers):\", len(model.layers)) # 1\n",
        "\n",
        "loss = ret.history['loss']\n",
        "print(\"loss:\", loss[-1])\n",
        "#print(model.get_weights())  # weights\n",
        "print(\"weights:\", model.layers[0].weights[0].numpy())\n",
        "\n",
        "plt.plot(loss)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(x, y_true) \n",
        "y_pred = model.predict(X)\n",
        "plt.plot(x, y_pred, color='red')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RcsgTEV2f5Xb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "5/5 - 0s - loss: 58.6691 - 197ms/epoch - 39ms/step\n",
            "Epoch 2/100\n",
            "5/5 - 0s - loss: 42.1066 - 4ms/epoch - 798us/step\n",
            "Epoch 3/100\n",
            "5/5 - 0s - loss: 36.8326 - 4ms/epoch - 798us/step\n",
            "Epoch 4/100\n",
            "5/5 - 0s - loss: 34.4049 - 4ms/epoch - 798us/step\n",
            "Epoch 5/100\n",
            "5/5 - 0s - loss: 32.4007 - 4ms/epoch - 798us/step\n",
            "Epoch 6/100\n",
            "5/5 - 0s - loss: 31.2255 - 5ms/epoch - 997us/step\n",
            "Epoch 7/100\n",
            "5/5 - 0s - loss: 28.2006 - 5ms/epoch - 997us/step\n",
            "Epoch 8/100\n",
            "5/5 - 0s - loss: 27.9486 - 4ms/epoch - 798us/step\n",
            "Epoch 9/100\n",
            "5/5 - 0s - loss: 24.6191 - 5ms/epoch - 997us/step\n",
            "Epoch 10/100\n",
            "5/5 - 0s - loss: 23.3354 - 4ms/epoch - 798us/step\n",
            "Epoch 11/100\n",
            "5/5 - 0s - loss: 22.3457 - 4ms/epoch - 798us/step\n",
            "Epoch 12/100\n",
            "5/5 - 0s - loss: 20.8812 - 4ms/epoch - 798us/step\n",
            "Epoch 13/100\n",
            "5/5 - 0s - loss: 19.7918 - 9ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "5/5 - 0s - loss: 18.2252 - 7ms/epoch - 1ms/step\n",
            "Epoch 15/100\n",
            "5/5 - 0s - loss: 16.6682 - 4ms/epoch - 798us/step\n",
            "Epoch 16/100\n",
            "5/5 - 0s - loss: 15.8955 - 5ms/epoch - 997us/step\n",
            "Epoch 17/100\n",
            "5/5 - 0s - loss: 15.4086 - 3ms/epoch - 598us/step\n",
            "Epoch 18/100\n",
            "5/5 - 0s - loss: 12.9778 - 4ms/epoch - 798us/step\n",
            "Epoch 19/100\n",
            "5/5 - 0s - loss: 12.1098 - 6ms/epoch - 1ms/step\n",
            "Epoch 20/100\n",
            "5/5 - 0s - loss: 10.8545 - 4ms/epoch - 798us/step\n",
            "Epoch 21/100\n",
            "5/5 - 0s - loss: 9.8995 - 4ms/epoch - 798us/step\n",
            "Epoch 22/100\n",
            "5/5 - 0s - loss: 9.8992 - 6ms/epoch - 1ms/step\n",
            "Epoch 23/100\n",
            "5/5 - 0s - loss: 9.0157 - 4ms/epoch - 798us/step\n",
            "Epoch 24/100\n",
            "5/5 - 0s - loss: 8.0169 - 5ms/epoch - 997us/step\n",
            "Epoch 25/100\n",
            "5/5 - 0s - loss: 6.8565 - 4ms/epoch - 798us/step\n",
            "Epoch 26/100\n",
            "5/5 - 0s - loss: 6.9980 - 5ms/epoch - 997us/step\n",
            "Epoch 27/100\n",
            "5/5 - 0s - loss: 6.0150 - 5ms/epoch - 997us/step\n",
            "Epoch 28/100\n",
            "5/5 - 0s - loss: 5.4772 - 4ms/epoch - 798us/step\n",
            "Epoch 29/100\n",
            "5/5 - 0s - loss: 5.4295 - 6ms/epoch - 1ms/step\n",
            "Epoch 30/100\n",
            "5/5 - 0s - loss: 4.4179 - 5ms/epoch - 997us/step\n",
            "Epoch 31/100\n",
            "5/5 - 0s - loss: 4.3484 - 4ms/epoch - 798us/step\n",
            "Epoch 32/100\n",
            "5/5 - 0s - loss: 4.5481 - 5ms/epoch - 997us/step\n",
            "Epoch 33/100\n",
            "5/5 - 0s - loss: 3.9658 - 5ms/epoch - 997us/step\n",
            "Epoch 34/100\n",
            "5/5 - 0s - loss: 3.3153 - 6ms/epoch - 1ms/step\n",
            "Epoch 35/100\n",
            "5/5 - 0s - loss: 3.0601 - 4ms/epoch - 798us/step\n",
            "Epoch 36/100\n",
            "5/5 - 0s - loss: 2.9836 - 4ms/epoch - 798us/step\n",
            "Epoch 37/100\n",
            "5/5 - 0s - loss: 3.1529 - 6ms/epoch - 1ms/step\n",
            "Epoch 38/100\n",
            "5/5 - 0s - loss: 3.0233 - 5ms/epoch - 997us/step\n",
            "Epoch 39/100\n",
            "5/5 - 0s - loss: 2.9799 - 6ms/epoch - 1ms/step\n",
            "Epoch 40/100\n",
            "5/5 - 0s - loss: 2.9698 - 5ms/epoch - 997us/step\n",
            "Epoch 41/100\n",
            "5/5 - 0s - loss: 2.8184 - 6ms/epoch - 1ms/step\n",
            "Epoch 42/100\n",
            "5/5 - 0s - loss: 2.5222 - 4ms/epoch - 798us/step\n",
            "Epoch 43/100\n",
            "5/5 - 0s - loss: 2.4833 - 3ms/epoch - 598us/step\n",
            "Epoch 44/100\n",
            "5/5 - 0s - loss: 2.9229 - 4ms/epoch - 798us/step\n",
            "Epoch 45/100\n",
            "5/5 - 0s - loss: 2.6166 - 3ms/epoch - 598us/step\n",
            "Epoch 46/100\n",
            "5/5 - 0s - loss: 2.5352 - 5ms/epoch - 997us/step\n",
            "Epoch 47/100\n",
            "5/5 - 0s - loss: 2.4602 - 5ms/epoch - 997us/step\n",
            "Epoch 48/100\n",
            "5/5 - 0s - loss: 2.2639 - 4ms/epoch - 798us/step\n",
            "Epoch 49/100\n",
            "5/5 - 0s - loss: 2.2405 - 5ms/epoch - 997us/step\n",
            "Epoch 50/100\n",
            "5/5 - 0s - loss: 2.8422 - 4ms/epoch - 798us/step\n",
            "Epoch 51/100\n",
            "5/5 - 0s - loss: 2.1802 - 4ms/epoch - 798us/step\n",
            "Epoch 52/100\n",
            "5/5 - 0s - loss: 2.6669 - 3ms/epoch - 598us/step\n",
            "Epoch 53/100\n",
            "5/5 - 0s - loss: 2.4690 - 4ms/epoch - 798us/step\n",
            "Epoch 54/100\n",
            "5/5 - 0s - loss: 2.7720 - 5ms/epoch - 997us/step\n",
            "Epoch 55/100\n",
            "5/5 - 0s - loss: 2.3054 - 4ms/epoch - 798us/step\n",
            "Epoch 56/100\n",
            "5/5 - 0s - loss: 2.3791 - 4ms/epoch - 798us/step\n",
            "Epoch 57/100\n",
            "5/5 - 0s - loss: 2.3440 - 4ms/epoch - 798us/step\n",
            "Epoch 58/100\n",
            "5/5 - 0s - loss: 2.3799 - 5ms/epoch - 997us/step\n",
            "Epoch 59/100\n",
            "5/5 - 0s - loss: 3.4941 - 8ms/epoch - 2ms/step\n",
            "Epoch 60/100\n",
            "5/5 - 0s - loss: 2.3281 - 4ms/epoch - 798us/step\n",
            "Epoch 61/100\n",
            "5/5 - 0s - loss: 2.2636 - 3ms/epoch - 598us/step\n",
            "Epoch 62/100\n",
            "5/5 - 0s - loss: 2.4327 - 4ms/epoch - 798us/step\n",
            "Epoch 63/100\n",
            "5/5 - 0s - loss: 2.5343 - 4ms/epoch - 798us/step\n",
            "Epoch 64/100\n",
            "5/5 - 0s - loss: 2.3665 - 4ms/epoch - 798us/step\n",
            "Epoch 65/100\n",
            "5/5 - 0s - loss: 2.3867 - 4ms/epoch - 798us/step\n",
            "Epoch 66/100\n",
            "5/5 - 0s - loss: 2.5757 - 4ms/epoch - 798us/step\n",
            "Epoch 67/100\n",
            "5/5 - 0s - loss: 2.3427 - 4ms/epoch - 798us/step\n",
            "Epoch 68/100\n",
            "5/5 - 0s - loss: 2.3824 - 4ms/epoch - 798us/step\n",
            "Epoch 69/100\n",
            "5/5 - 0s - loss: 2.6814 - 4ms/epoch - 798us/step\n",
            "Epoch 70/100\n",
            "5/5 - 0s - loss: 2.5725 - 4ms/epoch - 798us/step\n",
            "Epoch 71/100\n",
            "5/5 - 0s - loss: 2.5740 - 6ms/epoch - 1ms/step\n",
            "Epoch 72/100\n",
            "5/5 - 0s - loss: 2.6010 - 4ms/epoch - 798us/step\n",
            "Epoch 73/100\n",
            "5/5 - 0s - loss: 2.4850 - 3ms/epoch - 598us/step\n",
            "Epoch 74/100\n",
            "5/5 - 0s - loss: 2.4784 - 5ms/epoch - 997us/step\n",
            "Epoch 75/100\n",
            "5/5 - 0s - loss: 2.6706 - 4ms/epoch - 798us/step\n",
            "Epoch 76/100\n",
            "5/5 - 0s - loss: 2.5237 - 4ms/epoch - 798us/step\n",
            "Epoch 77/100\n",
            "5/5 - 0s - loss: 2.3911 - 4ms/epoch - 798us/step\n",
            "Epoch 78/100\n",
            "5/5 - 0s - loss: 2.0943 - 4ms/epoch - 798us/step\n",
            "Epoch 79/100\n",
            "5/5 - 0s - loss: 2.3008 - 4ms/epoch - 798us/step\n",
            "Epoch 80/100\n",
            "5/5 - 0s - loss: 2.5912 - 4ms/epoch - 798us/step\n",
            "Epoch 81/100\n",
            "5/5 - 0s - loss: 2.7129 - 4ms/epoch - 798us/step\n",
            "Epoch 82/100\n",
            "5/5 - 0s - loss: 2.3969 - 4ms/epoch - 798us/step\n",
            "Epoch 83/100\n",
            "5/5 - 0s - loss: 2.7750 - 4ms/epoch - 798us/step\n",
            "Epoch 84/100\n",
            "5/5 - 0s - loss: 2.2758 - 6ms/epoch - 1ms/step\n",
            "Epoch 85/100\n",
            "5/5 - 0s - loss: 2.2757 - 4ms/epoch - 798us/step\n",
            "Epoch 86/100\n",
            "5/5 - 0s - loss: 2.5804 - 4ms/epoch - 798us/step\n",
            "Epoch 87/100\n",
            "5/5 - 0s - loss: 2.8175 - 4ms/epoch - 798us/step\n",
            "Epoch 88/100\n",
            "5/5 - 0s - loss: 2.4807 - 4ms/epoch - 798us/step\n",
            "Epoch 89/100\n",
            "5/5 - 0s - loss: 2.3058 - 4ms/epoch - 798us/step\n",
            "Epoch 90/100\n",
            "5/5 - 0s - loss: 2.4762 - 4ms/epoch - 798us/step\n",
            "Epoch 91/100\n",
            "5/5 - 0s - loss: 2.5644 - 5ms/epoch - 997us/step\n",
            "Epoch 92/100\n",
            "5/5 - 0s - loss: 2.6535 - 3ms/epoch - 598us/step\n",
            "Epoch 93/100\n",
            "5/5 - 0s - loss: 2.4922 - 4ms/epoch - 798us/step\n",
            "Epoch 94/100\n",
            "5/5 - 0s - loss: 2.2410 - 4ms/epoch - 798us/step\n",
            "Epoch 95/100\n",
            "5/5 - 0s - loss: 2.4390 - 4ms/epoch - 798us/step\n",
            "Epoch 96/100\n",
            "5/5 - 0s - loss: 2.6684 - 4ms/epoch - 798us/step\n",
            "Epoch 97/100\n",
            "5/5 - 0s - loss: 2.0615 - 4ms/epoch - 798us/step\n",
            "Epoch 98/100\n",
            "5/5 - 0s - loss: 2.3800 - 4ms/epoch - 798us/step\n",
            "Epoch 99/100\n",
            "5/5 - 0s - loss: 2.3248 - 3ms/epoch - 598us/step\n",
            "Epoch 100/100\n",
            "5/5 - 0s - loss: 2.3745 - 4ms/epoch - 798us/step\n",
            "len(model.layers): 2\n",
            "loss: 2.3745274543762207\n",
            "weights: [[3.179723]]\n",
            "bias: [-10.980341]\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#1301\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def dataset(train_size=100): # tensorflow    \n",
        "     tf.random.set_seed(1)\n",
        "     x = tf.linspace(0.0, 10.0, num=train_size)\n",
        "     y = 3.0*x - 10.0\n",
        "     y += tf.random.normal([train_size], mean=0.0, stddev = 2.0)\n",
        "     return x, y\n",
        "x, y_true = dataset(20)\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(1,))\n",
        "##y = tf.keras.layers.Dense(units=1)  # ,input_shape=(1,))\n",
        "##outputs = y(inputs)\n",
        "outputs = tf.keras.layers.Dense(units=1)(inputs)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "\n",
        "##opt = tf.keras.optimizers.SGD(learning_rate=0.01)  # optimizer='sgd'\n",
        "##opt = tf.keras.optimizers.Adam(learning_rate=0.01) # 'adam'\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.1) # 'rmsprop'\n",
        "model.compile(optimizer=opt, loss='mse') # 'mean_squared_error'\n",
        "\n",
        "ret = model.fit(x, y_true, epochs=100, batch_size=4, verbose=2) #2: one line per epoch \n",
        "print(\"len(model.layers):\", len(model.layers)) # 2\n",
        "\n",
        "loss = ret.history['loss']\n",
        "print(\"loss:\", loss[-1])\n",
        "#print(model.get_weights())  # weights, bias\n",
        "print(\"weights:\", model.layers[1].weights[0].numpy())\n",
        "print(\"bias:\", model.layers[1].weights[1].numpy()) # model.layers[1].bias.numpy()\n",
        "\n",
        "plt.plot(loss)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(x, y_true)\n",
        "y_pred = model.predict(x)\n",
        "plt.plot(x, y_pred, color='red')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhIFj3UTgXtC"
      },
      "outputs": [],
      "source": [
        "#1302\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_data = np.array([ # t = 1*x0 + 2*x1 + 3\n",
        "#  x0, x1, t      \n",
        " [ 1,  0,  4],\n",
        " [ 2,  0,  5],\n",
        " [ 3,  0,  6],\n",
        " [ 4,  0,  7],\n",
        " [ 1,  1,  6],\n",
        " [ 2,  1,  7],\n",
        " [ 3,  1,  8],\n",
        " [ 4,  1,  9]], dtype=np.float32)\n",
        "\n",
        "X      = train_data[:, :-1]\n",
        "y_true = train_data[:, -1:]  # t\n",
        "##y_true += np.reshape(np.random.randn(len(y_true))*2.0, (-1, 1)) \n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(2,))\n",
        "##y = tf.keras.layers.Dense(units=1)  # ,input_shape=(2,))\n",
        "##outputs = y(inputs)\n",
        "outputs = tf.keras.layers.Dense(units=1)(inputs)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "\n",
        "##opt = tf.keras.optimizers.SGD(learning_rate=0.01)  # optimizer='sgd'\n",
        "##opt = tf.keras.optimizers.Adam(learning_rate=0.01) # 'adam'\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.1) # 'rmsprop'\n",
        "model.compile(optimizer=opt, loss='mse') # 'mean_squared_error'\n",
        "\n",
        "ret = model.fit(X, y_true, epochs=100, batch_size=4, verbose=2) # 2: one line per epoch\n",
        "y_pred = model.predict(X)\n",
        "print(\"y_pred:\", y_pred)\n",
        "print(\"len(model.layers):\", len(model.layers)) # 2\n",
        "\n",
        "loss = ret.history['loss']\n",
        "print(\"loss:\", loss[-1])\n",
        "#print(model.get_weights())\n",
        "print(\"weights:\", model.layers[1].weights[0].numpy())\n",
        "print(\"bias:\", model.layers[1].weights[1].numpy()) # model.layers[1].bias.numpy()\n",
        "\n",
        "plt.plot(loss)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EAONG0udgaSr"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#1303\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "#1303\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def dataset(train_size=100): # tensorflow    \n",
        "     tf.random.set_seed(1)\n",
        "     x = tf.linspace(-5.0, 5.0, num=train_size)\n",
        "     y = 3.0*x**3 + 2.0*x**2 + x + 4.0\n",
        "     y += tf.random.normal([train_size], mean=0.0, stddev = 30.0)\n",
        "     return x, y\n",
        "x, y_true = dataset(20)\n",
        "##x /= max(x)       # 정규화\n",
        "##y_true /= max(y_true)\n",
        "\n",
        "# n-차 다항식 회귀\n",
        "n = 3\n",
        "X = np.ones(shape = (len(x), n+1), dtype=np.float32)\n",
        "##X[:, 0] = 1.0\n",
        "##X[:, 1] = x\n",
        "##X[:, 2] = x**2\n",
        "##X[:, 3] = x**3\n",
        "for i in range(1, n+1):\n",
        "     X[:, i] = x**i\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(n+1,))\n",
        "outputs = tf.keras.layers.Dense(units=1, use_bias=False)(inputs)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "ret = model.fit(X, y_true, epochs=100, verbose=2)\n",
        "print(\"len(model.layers):\", len(model.layers)) # 2\n",
        "\n",
        "loss = ret.history['loss']\n",
        "print(\"loss:\", loss[-1])\n",
        "#print(model.get_weights())  # weights\n",
        "print(\"weights:\", model.layers[1].weights[0].numpy())\n",
        "\n",
        "plt.plot(loss)\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "plt.scatter(x, y_true) \n",
        "y_pred = model.predict(X)\n",
        "plt.plot(x, y_pred, color='red')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0jYciYKmgedy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 4)]               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4\n",
            "Trainable params: 4\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "1/1 - 0s - loss: 38632.6250 - 225ms/epoch - 225ms/step\n",
            "Epoch 2/100\n",
            "1/1 - 0s - loss: 31705.3496 - 2ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "1/1 - 0s - loss: 27329.4004 - 996us/epoch - 996us/step\n",
            "Epoch 4/100\n",
            "1/1 - 0s - loss: 24025.8574 - 2ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "1/1 - 0s - loss: 21345.7383 - 998us/epoch - 998us/step\n",
            "Epoch 6/100\n",
            "1/1 - 0s - loss: 19085.0938 - 2ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "1/1 - 0s - loss: 17131.7441 - 998us/epoch - 998us/step\n",
            "Epoch 8/100\n",
            "1/1 - 0s - loss: 15416.4941 - 2ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "1/1 - 0s - loss: 13893.2314 - 1ms/epoch - 1ms/step\n",
            "Epoch 10/100\n",
            "1/1 - 0s - loss: 12529.4668 - 998us/epoch - 998us/step\n",
            "Epoch 11/100\n",
            "1/1 - 0s - loss: 11301.2959 - 2ms/epoch - 2ms/step\n",
            "Epoch 12/100\n",
            "1/1 - 0s - loss: 10190.5342 - 2ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "1/1 - 0s - loss: 9182.9434 - 2ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "1/1 - 0s - loss: 8267.1094 - 2ms/epoch - 2ms/step\n",
            "Epoch 15/100\n",
            "1/1 - 0s - loss: 7433.6924 - 997us/epoch - 997us/step\n",
            "Epoch 16/100\n",
            "1/1 - 0s - loss: 6674.8994 - 3ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "1/1 - 0s - loss: 5984.1245 - 2ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "1/1 - 0s - loss: 5355.6782 - 2ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "1/1 - 0s - loss: 4784.5869 - 2ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "1/1 - 0s - loss: 4266.4487 - 2ms/epoch - 2ms/step\n",
            "Epoch 21/100\n",
            "1/1 - 0s - loss: 3797.3157 - 2ms/epoch - 2ms/step\n",
            "Epoch 22/100\n",
            "1/1 - 0s - loss: 3373.6042 - 2ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "1/1 - 0s - loss: 2992.0266 - 2ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "1/1 - 0s - loss: 2649.5386 - 999us/epoch - 999us/step\n",
            "Epoch 25/100\n",
            "1/1 - 0s - loss: 2343.2939 - 2ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "1/1 - 0s - loss: 2070.6133 - 2ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "1/1 - 0s - loss: 1828.9535 - 2ms/epoch - 2ms/step\n",
            "Epoch 28/100\n",
            "1/1 - 0s - loss: 1615.8900 - 2ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "1/1 - 0s - loss: 1429.1063 - 2ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "1/1 - 0s - loss: 1266.3743 - 2ms/epoch - 2ms/step\n",
            "Epoch 31/100\n",
            "1/1 - 0s - loss: 1125.5547 - 999us/epoch - 999us/step\n",
            "Epoch 32/100\n",
            "1/1 - 0s - loss: 1004.5907 - 2ms/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "1/1 - 0s - loss: 901.5109 - 998us/epoch - 998us/step\n",
            "Epoch 34/100\n",
            "1/1 - 0s - loss: 814.4247 - 2ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "1/1 - 0s - loss: 741.5337 - 2ms/epoch - 2ms/step\n",
            "Epoch 36/100\n",
            "1/1 - 0s - loss: 681.1309 - 2ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "1/1 - 0s - loss: 631.6102 - 2ms/epoch - 2ms/step\n",
            "Epoch 38/100\n",
            "1/1 - 0s - loss: 591.4723 - 997us/epoch - 997us/step\n",
            "Epoch 39/100\n",
            "1/1 - 0s - loss: 559.3301 - 2ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "1/1 - 0s - loss: 533.9153 - 2ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "1/1 - 0s - loss: 514.0824 - 2ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "1/1 - 0s - loss: 498.8109 - 997us/epoch - 997us/step\n",
            "Epoch 43/100\n",
            "1/1 - 0s - loss: 487.2060 - 2ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "1/1 - 0s - loss: 478.4963 - 997us/epoch - 997us/step\n",
            "Epoch 45/100\n",
            "1/1 - 0s - loss: 472.0285 - 3ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "1/1 - 0s - loss: 467.2619 - 3ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "1/1 - 0s - loss: 463.7574 - 2ms/epoch - 2ms/step\n",
            "Epoch 48/100\n",
            "1/1 - 0s - loss: 461.1675 - 997us/epoch - 997us/step\n",
            "Epoch 49/100\n",
            "1/1 - 0s - loss: 459.2241 - 2ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "1/1 - 0s - loss: 457.7254 - 2ms/epoch - 2ms/step\n",
            "Epoch 51/100\n",
            "1/1 - 0s - loss: 456.5251 - 998us/epoch - 998us/step\n",
            "Epoch 52/100\n",
            "1/1 - 0s - loss: 455.5186 - 2ms/epoch - 2ms/step\n",
            "Epoch 53/100\n",
            "1/1 - 0s - loss: 454.6357 - 996us/epoch - 996us/step\n",
            "Epoch 54/100\n",
            "1/1 - 0s - loss: 453.8289 - 997us/epoch - 997us/step\n",
            "Epoch 55/100\n",
            "1/1 - 0s - loss: 453.0692 - 2ms/epoch - 2ms/step\n",
            "Epoch 56/100\n",
            "1/1 - 0s - loss: 452.3380 - 2ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "1/1 - 0s - loss: 451.6243 - 998us/epoch - 998us/step\n",
            "Epoch 58/100\n",
            "1/1 - 0s - loss: 450.9228 - 2ms/epoch - 2ms/step\n",
            "Epoch 59/100\n",
            "1/1 - 0s - loss: 450.2296 - 2ms/epoch - 2ms/step\n",
            "Epoch 60/100\n",
            "1/1 - 0s - loss: 449.5429 - 2ms/epoch - 2ms/step\n",
            "Epoch 61/100\n",
            "1/1 - 0s - loss: 448.8619 - 3ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "1/1 - 0s - loss: 448.1862 - 2ms/epoch - 2ms/step\n",
            "Epoch 63/100\n",
            "1/1 - 0s - loss: 447.5148 - 2ms/epoch - 2ms/step\n",
            "Epoch 64/100\n",
            "1/1 - 0s - loss: 446.8481 - 998us/epoch - 998us/step\n",
            "Epoch 65/100\n",
            "1/1 - 0s - loss: 446.1855 - 2ms/epoch - 2ms/step\n",
            "Epoch 66/100\n",
            "1/1 - 0s - loss: 445.5267 - 998us/epoch - 998us/step\n",
            "Epoch 67/100\n",
            "1/1 - 0s - loss: 444.8713 - 2ms/epoch - 2ms/step\n",
            "Epoch 68/100\n",
            "1/1 - 0s - loss: 444.2196 - 997us/epoch - 997us/step\n",
            "Epoch 69/100\n",
            "1/1 - 0s - loss: 443.5706 - 998us/epoch - 998us/step\n",
            "Epoch 70/100\n",
            "1/1 - 0s - loss: 442.9246 - 997us/epoch - 997us/step\n",
            "Epoch 71/100\n",
            "1/1 - 0s - loss: 442.2812 - 2ms/epoch - 2ms/step\n",
            "Epoch 72/100\n",
            "1/1 - 0s - loss: 441.6406 - 2ms/epoch - 2ms/step\n",
            "Epoch 73/100\n",
            "1/1 - 0s - loss: 441.0019 - 3ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "1/1 - 0s - loss: 440.3657 - 2ms/epoch - 2ms/step\n",
            "Epoch 75/100\n",
            "1/1 - 0s - loss: 439.7311 - 2ms/epoch - 2ms/step\n",
            "Epoch 76/100\n",
            "1/1 - 0s - loss: 439.0982 - 999us/epoch - 999us/step\n",
            "Epoch 77/100\n",
            "1/1 - 0s - loss: 438.4672 - 2ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "1/1 - 0s - loss: 437.8380 - 2ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "1/1 - 0s - loss: 437.2101 - 2ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "1/1 - 0s - loss: 436.5836 - 997us/epoch - 997us/step\n",
            "Epoch 81/100\n",
            "1/1 - 0s - loss: 435.9587 - 2ms/epoch - 2ms/step\n",
            "Epoch 82/100\n",
            "1/1 - 0s - loss: 435.3352 - 997us/epoch - 997us/step\n",
            "Epoch 83/100\n",
            "1/1 - 0s - loss: 434.7134 - 2ms/epoch - 2ms/step\n",
            "Epoch 84/100\n",
            "1/1 - 0s - loss: 434.0934 - 2ms/epoch - 2ms/step\n",
            "Epoch 85/100\n",
            "1/1 - 0s - loss: 433.4747 - 2ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "1/1 - 0s - loss: 432.8582 - 2ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "1/1 - 0s - loss: 432.2437 - 3ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "1/1 - 0s - loss: 431.6315 - 3ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "1/1 - 0s - loss: 431.0217 - 995us/epoch - 995us/step\n",
            "Epoch 90/100\n",
            "1/1 - 0s - loss: 430.4151 - 2ms/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "1/1 - 0s - loss: 429.8116 - 998us/epoch - 998us/step\n",
            "Epoch 92/100\n",
            "1/1 - 0s - loss: 429.2119 - 998us/epoch - 998us/step\n",
            "Epoch 93/100\n",
            "1/1 - 0s - loss: 428.6161 - 997us/epoch - 997us/step\n",
            "Epoch 94/100\n",
            "1/1 - 0s - loss: 428.0252 - 3ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "1/1 - 0s - loss: 427.4391 - 997us/epoch - 997us/step\n",
            "Epoch 96/100\n",
            "1/1 - 0s - loss: 426.8587 - 2ms/epoch - 2ms/step\n",
            "Epoch 97/100\n",
            "1/1 - 0s - loss: 426.2843 - 997us/epoch - 997us/step\n",
            "Epoch 98/100\n",
            "1/1 - 0s - loss: 425.7166 - 997us/epoch - 997us/step\n",
            "Epoch 99/100\n",
            "1/1 - 0s - loss: 425.1563 - 997us/epoch - 997us/step\n",
            "Epoch 100/100\n",
            "1/1 - 0s - loss: 424.6042 - 2ms/epoch - 2ms/step\n"
          ]
        }
      ],
      "source": [
        "#1401\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def dataset(train_size=100): # tensorflow    \n",
        "     tf.random.set_seed(1)\n",
        "     x = tf.linspace(-5.0, 5.0, num=train_size)\n",
        "     y = 3.0*x**3 + 2.0*x**2 + x + 4.0\n",
        "     y += tf.random.normal([train_size], mean=0.0, stddev = 30.0)\n",
        "     return x, y\n",
        "\n",
        "x, y_true = dataset(20)\n",
        "\n",
        "# n-차 다항식 회귀\n",
        "n = 3\n",
        "X = np.ones(shape = (len(x), n+1), dtype=np.float32)\n",
        "for i in range(1, n+1):\n",
        "     X[:, i] = x**i\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(n+1,))\n",
        "outputs = tf.keras.layers.Dense(units=1, use_bias=False)(inputs)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "ret = model.fit(X, y_true, epochs=100, verbose=2)\n",
        "\n",
        "#1: 모델 전체 저장\n",
        "import os\n",
        "if not os.path.exists(\"./RES\"):\n",
        "     os.mkdir(\"./RES\")\n",
        "model.save(\"./RES/1401.h5\")   # HDF5, keras format\n",
        "\n",
        "#2: 모델 구조 저장\n",
        "json_string = model.to_json()\n",
        "import json\n",
        "file = open(\"./RES/1401.model\", 'w')\n",
        "json.dump(json_string, file)\n",
        "file.close()\n",
        " \n",
        "#3: 가중치 저장\n",
        "model.save_weights(\"./RES/weights/1401\")\n",
        " \n",
        "#4: 학습중에 체크포인트 저장\n",
        "filepath = \"RES/ckpt/1401-{epoch:04d}.ckpt\"\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "              filepath, verbose=0, save_weights_only=True, save_freq=50)\n",
        "ret = model.fit(X, y_true, epochs=100, callbacks = [cp_callback], verbose=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7BHuoMAgj8z"
      },
      "outputs": [],
      "source": [
        "#1402\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def dataset(train_size=100): # tensorflow    \n",
        "     tf.random.set_seed(1)\n",
        "     x = tf.linspace(-5.0, 5.0, num=train_size)\n",
        "     y = 3.0*x**3 + 2.0*x**2 + x + 4.0\n",
        "     y += tf.random.normal([train_size], mean=0.0, stddev = 30.0)\n",
        "     return x, y\n",
        "x, y_true = dataset(20)\n",
        "\n",
        "# n-차 다항식 회귀\n",
        "n = 3\n",
        "X = np.ones(shape = (len(x), n+1), dtype=np.float32)\n",
        "for i in range(1, n+1):\n",
        "     X[:, i] = x**i\n",
        "     \n",
        "#1: 모델 전체 로드\n",
        "model = tf.keras.models.load_model(\"./RES/1401.h5\")\n",
        "\n",
        "#2: 모델 평가, 예측, 그래프 표시\n",
        "loss = model.evaluate(X, y_true, verbose=0) # 0 = silent\n",
        "print(\"loss:\", loss)\n",
        "\n",
        "print(\"len(model.layers):\", len(model.layers)) # 2\n",
        "#print(model.get_weights())  # weights\n",
        "print(\"weights:\", model.layers[1].weights[0].numpy())\n",
        "\n",
        "#3: 예측, 그래프 표시\n",
        "plt.scatter(x, y_true) \n",
        "y_pred = model.predict(X)\n",
        "plt.plot(x, y_pred, color='red')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY9X0cwOgmqr"
      },
      "outputs": [],
      "source": [
        "#1403\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def dataset(train_size=100): # tensorflow    \n",
        "     tf.random.set_seed(1)\n",
        "     x = tf.linspace(-5.0, 5.0, num=train_size)\n",
        "     y = 3.0*x**3 + 2.0*x**2 + x + 4.0\n",
        "     y += tf.random.normal([train_size], mean=0.0, stddev = 30.0)\n",
        "     return x, y\n",
        "x, y_true = dataset(20)\n",
        "\n",
        "# n-차 다항식 회귀\n",
        "n = 3\n",
        "X = np.ones(shape = (len(x), n+1), dtype=np.float32)\n",
        "for i in range(1, n+1):\n",
        "     X[:, i] = x**i\n",
        "\n",
        "##inputs = tf.keras.layers.Input(shape=(n+1,))\n",
        "##outputs = tf.keras.layers.Dense(units=1, use_bias=False)(inputs)\n",
        "##model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "##model.summary()\n",
        "\n",
        "#1: 모델 구조 로드\n",
        "import json\n",
        "file = open(\"./RES/1401.model\", 'r')\n",
        "json_model = json.load(file)\n",
        "file.close()\n",
        "model = tf.keras.models.model_from_json(json_model)\n",
        "model.summary()\n",
        "\n",
        "#2\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "#3\n",
        "model.load_weights(\"./RES/weights/1401\")    # 가중치 로드 \n",
        "loss = model.evaluate(X, y_true, verbose=0) # 0 = silent\n",
        "print(\"loss:\", loss)\n",
        "print(\"len(model.layers):\", len(model.layers)) # 1\n",
        "#print(model.get_weights())  # weights\n",
        "print(\"weights:\", model.layers[1].weights[0].numpy())\n",
        "\n",
        "#4\n",
        "y_pred = model.predict(X)\n",
        "plt.scatter(x, y_true) \n",
        "plt.plot(x, y_pred, color='red')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3KVbPkPgpRb"
      },
      "outputs": [],
      "source": [
        "#1404\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def dataset(train_size=100): # tensorflow    \n",
        "     tf.random.set_seed(1)\n",
        "     x = tf.linspace(-5.0, 5.0, num=train_size)\n",
        "     y = 3.0*x**3 + 2.0*x**2 + x + 4.0\n",
        "     y += tf.random.normal([train_size], mean=0.0, stddev = 30.0)\n",
        "     return x, y\n",
        "x, y_true = dataset(20)\n",
        "\n",
        "# n-차 다항식 회귀\n",
        "n = 3\n",
        "X = np.ones(shape = (len(x), n+1), dtype=np.float32)\n",
        "for i in range(1, n+1):\n",
        "     X[:, i] = x**i\n",
        "\n",
        "##inputs = tf.keras.layers.Input(shape=(n+1,))\n",
        "##outputs = tf.keras.layers.Dense(units=1, use_bias=False)(inputs)\n",
        "##model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "##model.summary()\n",
        "\n",
        "#1: 모델 구조 로드\n",
        "import json\n",
        "file = open(\"./RES/1401.model\", 'r')\n",
        "json_model = json.load(file)\n",
        "file.close()\n",
        "model = tf.keras.models.model_from_json(json_model)\n",
        "model.summary()\n",
        "\n",
        "#2\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "\n",
        "#3\n",
        "latest = tf.train.latest_checkpoint(\"./RES/ckpt\")\n",
        "print('latest=', latest)\n",
        "model.load_weights(latest) # 가중치 로드 \n",
        "loss = model.evaluate(X, y_true, verbose=0) # 0 = silent\n",
        "print(\"loss:\", loss)\n",
        "print(\"len(model.layers):\", len(model.layers)) # 2\n",
        "#print(model.get_weights())  # weights\n",
        "print(\"weights:\", model.layers[1].weights[0].numpy())\n",
        "\n",
        "#4\n",
        "y_pred = model.predict(X)\n",
        "plt.scatter(x, y_true) \n",
        "plt.plot(x, y_pred, color='red')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7YmCk_VgsGb"
      },
      "outputs": [],
      "source": [
        "#1405\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def dataset(train_size=100): # tensorflow    \n",
        "     tf.random.set_seed(1)\n",
        "     x = tf.linspace(-5.0, 5.0, num=train_size)\n",
        "     y = 3.0*x**3 + 2.0*x**2 + x + 4.0\n",
        "     y += tf.random.normal([train_size], mean=0.0, stddev = 30.0)\n",
        "     return x, y\n",
        "x, y_true = dataset(20)\n",
        "\n",
        "# n-차 다항식 회귀\n",
        "n = 3\n",
        "X = np.ones(shape = (len(x), n+1), dtype=np.float32)\n",
        "for i in range(1, n+1):\n",
        "     X[:, i] = x**i\n",
        "\n",
        "inputs = tf.keras.layers.Input(shape=(n+1,))\n",
        "outputs = tf.keras.layers.Dense(units=1, use_bias=False)(inputs)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model.summary()\n",
        "\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n",
        "model.compile(optimizer=opt, loss='mse')\n",
        "ret = model.fit(X, y_true, epochs=100, verbose=2)\n",
        "\n",
        "#모델 동결(Freezing)\n",
        "#ref1: https://github.com/leimao/Frozen_Graph_TensorFlow/blob/master/TensorFlow_v2/test.py\n",
        "#ref2: https://leimao.github.io/blog/Save-Load-Inference-From-TF2-Frozen-Graph/\n",
        "\n",
        "#1: 모델을 하나의 시스니쳐를 갖는 ConcreteFunction으로 변환\n",
        "full_model = tf.function(lambda x: model(x))\n",
        "full_model = full_model.get_concrete_function(\n",
        "        tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype))\n",
        "\n",
        "#2: 동결함수 생성\n",
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
        "frozen_func = convert_variables_to_constants_v2(full_model)\n",
        "\n",
        "#3: 동결 그래프(frozen graph) 저장\n",
        "tf.io.write_graph(graph_or_graph_def=frozen_func.graph,\n",
        "                      logdir=\"./RES\",\n",
        "                      name=\"frozen_graph.pb\",\n",
        "                      as_text=False)\n",
        "\n",
        "#4: 모델구조 화면출력\n",
        "##print(frozen_func.graph.as_graph_def())\n",
        "##\n",
        "##layers = [op.name for op in frozen_func.graph.get_operations()]\n",
        "##print(\"-\"* 20)\n",
        "##print(\"model layers: \")\n",
        "##for layer in layers:\n",
        "##     print(layer)\n",
        "##\n",
        "##print(\"-\" * 20)\n",
        "##print(\"model inputs: \")\n",
        "##print(frozen_func.inputs)\n",
        "##print(\"model outputs: \")\n",
        "##print(frozen_func.outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO2QkI6ugvBE"
      },
      "outputs": [],
      "source": [
        "#1406\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 # pip install opencv-contrib-python\n",
        "\n",
        "def dataset(train_size=100): # tensorflow    \n",
        "     tf.random.set_seed(1)\n",
        "     x = tf.linspace(-5.0, 5.0, num=train_size)\n",
        "     y = 3.0*x**3 + 2.0*x**2 + x + 4.0\n",
        "     y += tf.random.normal([train_size], mean=0.0, stddev = 30.0)\n",
        "     return x, y\n",
        "x, y_true = dataset(20)\n",
        "\n",
        "# n-차 다항식 회귀\n",
        "n = 3\n",
        "X = np.ones(shape = (len(x), n+1), dtype=np.float32)\n",
        "for i in range(1, n+1):\n",
        "     X[:, i] = x**i\n",
        "\n",
        "#텐서플로 모델, 학습결과 로드\n",
        "fname = \"./RES/frozen_graph.pb\"\n",
        "net =cv2.dnn.readNetFromTensorflow(fname)\n",
        "##net =cv2.dnn.readNetFromTensorflow(np.fromfile(fname, dtype=np.uint8))#한글 path\n",
        "##for xx in X:\n",
        "##    blob = cv2.dnn.blobFromImage(xx)\n",
        "##    net.setInput(blob)\n",
        "##    res = net.forward()\n",
        "##    print(xx, res)\n",
        "     \n",
        "blob = cv2.dnn.blobFromImages(X) # blob.shape = (20, 1, 4, 1)\n",
        "net.setInput(blob) \n",
        "y_pred = net.forward()\n",
        "\n",
        "plt.scatter(x, y_true) \n",
        "plt.plot(x, y_pred, color='red')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
