{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2gFVVyo89yG"
      },
      "source": [
        "# CNN(Convolutional Neural Network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rjE6m-a9D_d"
      },
      "source": [
        "- 합성곱 층(Convolution layer) 과 완전 연결 층(Dense layer)의 차이\n",
        "\n",
        "  - 완전 연결 층은 입력 이미지 전역 패턴 학습하지만, 합성곱 층은 입력 이미지 지역 패턴 학습한다.\n",
        "  - 특징\n",
        "    - 평행이동 불변성: 평행이동 된 지역 패턴은 같은 패턴으로 인식한다. <br> 이는 합성곱 신경망이 효율적으로 지역 패턴 학습하게 한다. <br> 또, 인간 두뇌가 객체 인식하는 방법과 같다.\n",
        "    - 객체를 계층적 인식: 컨브넷은 객체를 계층적으로 인식한다. <br> 각 위치 에지, 질감에서 시작해서 귀, 코, 눈 등 더 상위 개념을 순차.계층적으로 인식해간다. <br> 두뇌가 객체 인식하는 방법과 같다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xozGM5fM9X_h"
      },
      "source": [
        "- 합성곱 연산\n",
        "  - 합성곱 층은 입력 이미지 받아 합성곱 연산 수행하고, 결과 출력한다.\n",
        "  - 합성곱 연산은 입력 이미지 모든 위치에서 지역 패턴들 추출한다.\n",
        "  - 지역패턴에는 에지(Edge), 질감(Texture) 등 포함된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWYulnpR9f3-"
      },
      "source": [
        "- 합성곱 연산 과정\n",
        "  1. 입력 이미지 위를 3 × 3 또는 5 × 5 크기 윈도우가 슬라이딩(Sliding) 하며 3 × 3 또는 5 × 5 크기 패치(Patch:작은 조각) \n",
        "추출한다. <br> (윈도우 사이즈 크기 패치 추출한다)\n",
        "  2. 각 패치와. 에지, 질감 등 지역 특징 담고있는 필터(또는 커널)를 요소별 텐서 곱 연산 한다.\n",
        "  3. 텐서 곱 연산 결과 모두 합한다. 곧, 2 과정은 패치 각 요소를 가중합 한 것과 같다.\n",
        "  4. <3> 결과를 특성 맵(Feature Map) 또는 응답 맵(Responsse Map) 이라고 한다. <br> 입력 이미지 각 위치에 그 필터 패턴이 \n",
        "나타나 있었는지 확인. 응답한 결과다.\n",
        "  5. 입력 이미지 각 채널(예: RGB 3개) 별로 각각 다른 필터 적용된다.\n",
        "    - 1개 합성곱 층에서 입력 이미지에 대해 여러 개 필터 적용한다(예: 32개, 64개, 128개…).\n",
        "    - 보통 1개 합성곱 층 필터 개수는 하위 층에서 상위 층 갈 수록 2 제곱 수로 점차 증가시켜 간다.\n",
        "    - 일반 경우, 합성곱 하위 층에서 상위 층(더 깊은 층) 갈 수록, 각 층의 출력 특성 맵 크기는 줄어든다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvqhVnjP93R7"
      },
      "source": [
        "- 패딩\n",
        "  - Zero Padding\n",
        "    - 입력 특성 맵과 출력 특성 맵 크기를 같게 하고 싶으면 입력 특성 맵에 패딩(Padding) 추가하면 된다.\n",
        "    - 입력 특성 맵 가장자리에 적절한 개수 행과 열 추가하는 걸 패딩이라 한다.\n",
        "    - 패딩 자리에 보통 0 넣기 때문에, 제로 패딩 이라고도 한다.\n",
        "    - 위 행렬에 대해 합성곱 하면 출력 특성 맵 크기가 입력 특성 맵과 같아진다 (5∗5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F91XIaty-SZ3"
      },
      "source": [
        "- 케라스에서 패딩 사용하기\n",
        "  - Conv2D 층에서 padding 파라미터 설정하면 된다. ‘valid’ 는 패딩 사용 안함, ‘same’은 패딩 사용함 이다.\n",
        "  - 기본 파라미터는 valid (패딩 사용 안함) 이다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILYt2DEx-WUw"
      },
      "source": [
        "- 스트라이드(Stride): 보폭\n",
        "  - 연속한 두 윈도우 사이 거리를 스트라이드 라고 한다.\n",
        "  - 스트라이드 값 기본은 1이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1VtMrom-e5u"
      },
      "source": [
        "- 최대 풀링 연산\n",
        "  - 합성 곱 층 출력 특성맵 받아 다운샘플링(행렬 크기 줄이기) 하는 연산이다.\n",
        "  - 2∗2 윈도우와 스트라이드 2 사용해서, 패치 별로 최댓값만 추출한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kehARR8a-jjI"
      },
      "source": [
        "- 최대 풀링 연산 목적\n",
        "  - 입력을 다운샘플링 해서, 특성 맵 가중치 개수를 줄인다.\n",
        "  - 모델이 공간적 계층 구조 학습하는 걸 돕는다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83f5cUj--m6t"
      },
      "source": [
        "## 간단한 컨브넷 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c04ZiEgw-sdP"
      },
      "source": [
        "### MNIST 이미지 분류하는 간단한 컨브넷 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "LeQp7Q4FpwL8",
        "outputId": "5be70d50-68d3-4f07-edb7-17873f97b8f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 13, 13, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 5, 5, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 576)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 64)                36928     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "188/188 - 1s - loss: 0.0414 - accuracy: 0.9875 - 1s/epoch - 6ms/step\n",
            "313/313 - 2s - loss: 0.0934 - accuracy: 0.9697 - 2s/epoch - 6ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#1\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# subsampling for overfitting\n",
        "n_sample = 6000\n",
        "x_train = x_train[:n_sample]\n",
        "y_train = y_train[:n_sample]\n",
        "\n",
        "#2:normalize images\n",
        "x_train = x_train.astype('float32')\n",
        "x_test  = x_test.astype('float32')\n",
        "x_train /= 255.0 # [0, 1]\n",
        "x_test  /= 255.0\n",
        "\n",
        "#3: one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train) # (n_sample, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)   # (10000,    10)\n",
        "\n",
        "#4: build a model with dropout\n",
        "act = \"sigmoid\"\n",
        "# act = \"relu\"\n",
        "init = \"he_uniform\"\n",
        "\n",
        "# 간단한 컨브넷 작성\n",
        "# 이미지 특징 추출 층(합성곱 기반 층)\n",
        "model = models.Sequential()\n",
        "# 필터 수, 패치 사이즈(3*3), 요소별 적용할 활성화 함수, 입력 특성 맵 사이즈\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "# activation='relu' : 음수와 0은 모두 0, 양수값만 남김\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())  # 특성공학 결과물 1차원 텐서(벡터)로 변환하는 층\n",
        "\n",
        "# 완전 연결 분류기\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))  # 출력층 : 최상위층, 분류 결과물 확률 꼴로 변환\n",
        "\n",
        "# 모델 설계 결과 요약\n",
        "model.summary()\n",
        "\n",
        "#4-1: configure the model for training\n",
        "##opt = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "# 모델 컴파일(학습 준비 - Optimizer, loss function, 성능 측정 metric 지정)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#4-2: train and evaluate the model\n",
        "# 모델 학습\n",
        "ret = model.fit(x_train, y_train, epochs=5, batch_size=64,\n",
        "                validation_data = (x_test, y_test), verbose=0)\n",
        "\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train, verbose=2)\n",
        "test_loss, test_acc   = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "#4-3: plot accuracies\n",
        "plt.title(\"Dropout rate = %s, %s traing data in mnist\"%(dropout_rate, n_sample))\n",
        "plt.plot(ret.history['accuracy'],     \"b-\", label=\"train accuracy\")\n",
        "plt.plot(ret.history['val_accuracy'], \"r-\", label=\"val accuracy\")\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGQc1lX5qBE_",
        "outputId": "36310bfe-d0f2-4af8-c917-2614d8a97952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#1\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#2:normalize images\n",
        "x_train = x_train.astype('float32')\n",
        "x_test  = x_test.astype('float32')\n",
        "x_train /= 255.0 # [0, 1]a\n",
        "x_test  /= 255.0\n",
        "\n",
        "#3: one-hot encoding\n",
        "y_train = tf.keras.utils.to_categorical(y_train) # (50000, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)   # (10000, 10)\n",
        "\n",
        "#4: build a model with dropout\n",
        "act =  tf.keras.layers.LeakyReLU(alpha=0.3) #'relu','sigmoid'\n",
        "init = 'he_uniform'\n",
        "\n",
        "n = 10\n",
        "dropout_rate = 0.2 # 0.5\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary\n",
        "\n",
        "#4-1: configure the model for training\n",
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "model.compile(optimizer='rmsprop', \n",
        "            loss='categorical_crossentropy', \n",
        "            metrics=['accuracy'])\n",
        "\n",
        "#4-2: train and evaluate the model\n",
        "ret = model.fit(x_train, y_train, \n",
        "                epochs=5, batch_size=64,\n",
        "                validation_data = (x_test, y_test), verbose=0)\n",
        "\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train, verbose=2)\n",
        "test_loss, test_acc   = model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "#4-3: plot accuracies\n",
        "plt.plot(ret.history['accuracy'],     \"b-\", label=\"train accuracy\")\n",
        "plt.plot(ret.history['val_accuracy'], \"r-\", label=\"val accuracy\")\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E-FEBOQ8wAH"
      },
      "source": [
        "### Kaggle 개 vs 고양이 데이터 소개\n",
        "\n",
        "- Total training cat image: 1000 개 \n",
        "- Total training dog image: 1000 개 \n",
        "- Total validation cat image: 500 개 \n",
        "- Total validation dog image: 500 개"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VMFVMZg06G3",
        "outputId": "7de16163-f49e-478a-e8fe-b69fefa99006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               3211776   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 네트워크 구성\n",
        "\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "# 입력 특성 맵에 적용할 필터 수 : 32, 윈도우 사이즈, 활성화함수, 입력 데이터 규격 : 150*150, RGB 3채널\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # 최대 풀링 연산 적용할 윈도우 사이즈 - 다운샘플링(크기 축소)\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))  # 입력 특성 맵에 적용할 필터 수 : 64, 윈도우 사이즈, 활성화 함수\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # 윈도우 사이즈\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))  # 필터 수 : 128개, 윈도우 사이즈\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # 윈도우 사이즈\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))  # 필터 수 : 128개, 윈도우 사이즈\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # 윈도우 사이즈\n",
        "# 여기까지 합성곱 기반 층(지역 패턴 추출 층)\n",
        "\n",
        "# 여기서부터 완전 연결 층(전역 패턴 추출, 분류기)\n",
        "model.add(layers.Flatten())  # 1차원 텐서(벡터)로 변환\n",
        "model.add(layers.Dense(512, activation='relu'))  # 512차원 벡터공간에 투영\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "# 1. 150*150 입력 이미지에서 3*3 윈도우 슬라이딩하면서 3*3 패치 추출 -> 32개 필터에 대해 합성곱 -> 148*148*32\n",
        "# 2. 2*2 윈도우 1의 출력 특성 맵에 적용해서 패치 구역별 최댓값만 추출 -> 출력 특성 맵 크기가 절반으로 줄어듦 -> 74*74*32\n",
        "# 3. 2의 출력 특성 맵에서 다시 3*3 패치 추출 -> 64개 필터에 대해 합성곱 -> 72*72*64\n",
        "# 4. 2번처럼 최대 풀링 연산 3 출력에 적용 -> 출력 특성 맵 크기 절반으로 줄어듦 -> 36*36*64\n",
        "# 5. 3*3 패치, 128개 필터에 대해 합성곱 -> 34*34*128\n",
        "# 6. 최대 풀링 연산 적용 -> 17*17*128\n",
        "# 7. 3*3 패치, 128개 필터에 대해 합성곱 -> 15*15*128\n",
        "# 8. 최대 풀링 연산 적용 -> 7*7*128\n",
        "# 9. 완전 연결 분류기 주입 위해 1차원 텐서(벡터)로 변환하는 층\n",
        "# 10. 512차원 벡터공간에 투영\n",
        "# 11. 1차원 벡터공간으로 차원축소 후 시그모이드 함수 적용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 148, 148, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 74, 74, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 72, 72, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 34, 34, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 15, 15, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               3211776   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,454,529\n",
            "Trainable params: 3,453,825\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# BatchNormalization layer 추가\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "# 입력 특성 맵에 적용할 필터 수 : 32, 윈도우 사이즈, 활성화함수, 입력 데이터 규격 : 150*150, RGB 3채널\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # 최대 풀링 연산 적용할 윈도우 사이즈 - 다운샘플링(크기 축소)\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))  # 입력 특성 맵에 적용할 필터 수 : 64, 윈도우 사이즈, 활성화 함수\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # 윈도우 사이즈\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))  # 필터 수 : 128개, 윈도우 사이즈\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # 윈도우 사이즈\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))  # 필터 수 : 128개, 윈도우 사이즈\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # 윈도우 사이즈\n",
        "# 여기까지 합성곱 기반 층(지역 패턴 추출 층)\n",
        "\n",
        "# 여기서부터 완전 연결 층(전역 패턴 추출, 분류기)\n",
        "model.add(layers.Flatten())  # 1차원 텐서(벡터)로 변환\n",
        "model.add(layers.Dense(512, activation='relu'))  # 512차원 벡터공간에 투영\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dropout layer 추가\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "dropout_rate = 0.2  # 0.5\n",
        "model = models.Sequential()\n",
        "# 입력 특성 맵에 적용할 필터 수 : 32, 윈도우 사이즈, 활성화함수, 입력 데이터 규격 : 150*150, RGB 3채널\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(tf.keras.layers.Dropout( rate=dropout_rate))\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # 최대 풀링 연산 적용할 윈도우 사이즈 - 다운샘플링(크기 축소)\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))  # 입력 특성 맵에 적용할 필터 수 : 64, 윈도우 사이즈, 활성화 함수\n",
        "model.add(tf.keras.layers.Dropout( rate=dropout_rate))\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # 윈도우 사이즈\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))  # 필터 수 : 128개, 윈도우 사이즈\n",
        "model.add(tf.keras.layers.Dropout( rate=dropout_rate))\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # 윈도우 사이즈\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))  # 필터 수 : 128개, 윈도우 사이즈\n",
        "model.add(tf.keras.layers.Dropout( rate=dropout_rate))\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # 윈도우 사이즈\n",
        "# 여기까지 합성곱 기반 층(지역 패턴 추출 층)\n",
        "\n",
        "# 여기서부터 완전 연결 층(전역 패턴 추출, 분류기)\n",
        "model.add(layers.Flatten())  # 1차원 텐서(벡터)로 변환\n",
        "model.add(layers.Dense(512, activation='relu'))  # 512차원 벡터공간에 투영\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aHj5e_fH5AqR"
      },
      "outputs": [],
      "source": [
        "# 모델 컴파일\n",
        "from keras import optimizers\n",
        "\n",
        "model.compile(\n",
        "    loss = 'binary_crossentropy',\n",
        "    optimizer = optimizers.adam_v2.Adam(learning_rate=0.001),\n",
        "    metrics=['acc']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "QXoU66Oo5Xzn",
        "outputId": "5928eace-b06e-47df-a326-a19f4a6b1daa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# 데이터 전처리\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)  # 스케일 1/255로 조정, 부동소수점 형태로 변환\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # 스케일 조정\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'C:/Users/user/Desktop/cats_and_dogs_small/train',\n",
        "    target_size=(150, 150),  # 네트워크 입력 규격에 맞게 크기 변환\n",
        "    batch_size=20,  # 1에폭 동안 투입할 데이터 묶음\n",
        "    class_mode='binary'  # 데이터가 이진 레이블임\n",
        ")\n",
        "\n",
        "valid_generator = test_datagen.flow_from_directory(\n",
        "    'C:/Users/user/Desktop/cats_and_dogs_small/test',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8kEnY891_jFD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9000\\2097167460.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 29s 283ms/step - loss: 1.2501 - acc: 0.5975 - val_loss: 1.3271 - val_acc: 0.5000\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.5817 - acc: 0.7050 - val_loss: 0.9861 - val_acc: 0.5020\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 31s 306ms/step - loss: 0.4945 - acc: 0.7645 - val_loss: 0.9708 - val_acc: 0.5560\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.4401 - acc: 0.7925 - val_loss: 0.8696 - val_acc: 0.6280\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.3329 - acc: 0.8670 - val_loss: 0.9451 - val_acc: 0.6360\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.1898 - acc: 0.9230 - val_loss: 0.7427 - val_acc: 0.7000\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.1044 - acc: 0.9615 - val_loss: 1.0247 - val_acc: 0.6990\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.1212 - acc: 0.9540 - val_loss: 0.9595 - val_acc: 0.6760\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.1003 - acc: 0.9615 - val_loss: 1.1173 - val_acc: 0.6920\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.0549 - acc: 0.9825 - val_loss: 0.8983 - val_acc: 0.7320\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0317 - acc: 0.9925 - val_loss: 1.0576 - val_acc: 0.7180\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0289 - acc: 0.9925 - val_loss: 1.0425 - val_acc: 0.7100\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0111 - acc: 0.9970 - val_loss: 1.0359 - val_acc: 0.7240\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0162 - acc: 0.9940 - val_loss: 1.1512 - val_acc: 0.7200\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0627 - acc: 0.9800 - val_loss: 1.6900 - val_acc: 0.6270\n",
            "Epoch 16/30\n",
            " 65/100 [==================>...........] - ETA: 9s - loss: 0.1476 - acc: 0.9446"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9000\\2097167460.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 모델 훈련\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit_generator(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 20*100 = 총 훈련 데이터 갯수\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2505\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2506\u001b[0m         )\n\u001b[1;32m-> 2507\u001b[1;33m         return self.fit(\n\u001b[0m\u001b[0;32m   2508\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2509\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 모델 훈련\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=100,  # 20*100 = 총 훈련 데이터 갯수\n",
        "    epochs = 30,\n",
        "    validation_data = valid_generator,\n",
        "    validation_steps = 50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j_HIEr7__kXL"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9000\\2769910028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ],
      "source": [
        "# 훈련 및 검증 정확도, 훈련 및 검증 손실 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss, 'bo', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.suptitle('Accuracy & Loss')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
